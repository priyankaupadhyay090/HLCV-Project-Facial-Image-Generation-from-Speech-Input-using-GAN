{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "from pathlib import Path\n",
    "from importlib import reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import speech_dataset\n",
    "reload(speech_dataset)\n",
    "\n",
    "PARENT_DIR = Path().resolve()\n",
    "DATA_DIR = PARENT_DIR / 'preprocess' / 'mmca'\n",
    "\n",
    "train_data = speech_dataset.SpeechImgDataset(DATA_DIR, 'train')\n",
    "test_data = speech_dataset.SpeechImgDataset(DATA_DIR, 'test')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "            train_data, batch_size=2,\n",
    "            drop_last=True, shuffle=True, num_workers=0, collate_fn=speech_dataset.pad_collate)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "            test_data, batch_size=2,\n",
    "            drop_last=False, shuffle=False, num_workers=0, collate_fn=speech_dataset.pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\tomas\\anaconda3\\lib\\site-packages\\torchvision\\models\\inception.py:80: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn('The default weight initialization of inception_v3 will be changed in future releases of '\n",
      "Loading pre-trained model from  https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\n"
     ]
    }
   ],
   "source": [
    "from network import sed, ied\n",
    "reload(sed)\n",
    "reload(ied)\n",
    "\n",
    "speech_model = sed.SED()\n",
    "image_model = ied.Inception_V3_Model()\n",
    "linear_model = ied.Linear_Encoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "starting training\n",
      "epoch = 5 | loss = 2.100271701812744 \n",
      "epoch = 10 | loss = 1.30936861038208 \n",
      "epoch = 15 | loss = 1.085029125213623 \n",
      "epoch = 20 | loss = 1.4617431163787842 \n",
      "epoch = 25 | loss = 1.4466431140899658 \n",
      "epoch = 30 | loss = 1.4680016040802002 \n",
      "epoch = 35 | loss = 1.3343510627746582 \n",
      "epoch = 40 | loss = 1.4358081817626953 \n",
      "epoch = 45 | loss = 1.4503183364868164 \n",
      "epoch = 50 | loss = 1.3858928680419922 \n",
      "epoch = 55 | loss = 1.3912097215652466 \n",
      "epoch = 60 | loss = 1.4018744230270386 \n",
      "epoch = 65 | loss = 1.4228427410125732 \n",
      "epoch = 70 | loss = 1.3772001266479492 \n",
      "epoch = 75 | loss = 1.4355417490005493 \n",
      "epoch = 80 | loss = 1.3607988357543945 \n",
      "epoch = 85 | loss = 1.4047211408615112 \n",
      "epoch = 90 | loss = 1.3997230529785156 \n",
      "epoch = 95 | loss = 1.4162702560424805 \n",
      "epoch = 100 | loss = 1.4144558906555176 \n"
     ]
    }
   ],
   "source": [
    "import pretrain\n",
    "\n",
    "pretrain.train(train_loader, test_loader, speech_model, image_model, linear_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "4d333c3e79956f6cfdda154d497169890c9e1b3b648807dd58683480f0849f8e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}